{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling with SKLearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "Let's start with something straightforward: classification with logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy 98.0%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# set up our sklearn data shape for the iris data\n",
    "df = pd.read_csv(\"assets/iris.csv\")\n",
    "X  = df.drop(['id','Species'],axis=1)\n",
    "y = df['Species']\n",
    "\n",
    "# set up our model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(C=1000.0)\n",
    "\n",
    "# train the model\n",
    "model.fit(X, y)\n",
    "\n",
    "# check out the training error\n",
    "print(\"Training Accuracy {}%\".format(model.score(X, y)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Curves\n",
    "\n",
    "* It can be shown that *any model* can learn its training data perfectly - “memorize it”\n",
    "* But memorizing is not the same as learning inherent patterns and use those patterns to make predictions!\n",
    "\n",
    "> Memorization does not generalize well!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we train a model using *training data* and then apply the model to a *validation data set* then we obtain these following typical curves:\n",
    "\n",
    "<!-- ![model curves](assets/model-performance-curves.png) -->\n",
    "\n",
    "<img src=\"assets/model-performance-curves.png\"  height=\"200\" width=\"400\">\n",
    "\n",
    "Note: Validation data is data that the model has not seen yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simply put:\n",
    "\n",
    "1. Undertrained models make a lot of errors on validation data because they have not learned any of the patterns yet.\n",
    "\n",
    "2. Overtrained models (models that have memorized their training data) make a lot of errors on validation data because they believe the noise in the data are patterns.\n",
    "\n",
    "3. The best models make a trade-off between errors and recognizing important patterns. Notice that for the best models the training score is not 100%!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# import the function we need to train-test\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# set up our model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(C=1000.0)\n",
    "\n",
    "# set up our sklearn data shape for the iris data\n",
    "df = pd.read_csv(\"assets/iris.csv\")\n",
    "X  = df.drop(['id','Species'],axis=1)\n",
    "y = df['Species']\n",
    "\n",
    "# split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2)\n",
    "\n",
    "# fit the model on the training set of data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# evaluate the model on the testing set of data\n",
    "y_test_model = model.predict(X_test)\n",
    "\n",
    "# output the results\n",
    "print(\"Accuracy: {}\".format(accuracy_score(y_test, y_test_model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observe:** the model parameters that gave us the best results on the training data do not necessarily give us the best results on the testing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation\n",
    "\n",
    "### Problem!\n",
    "\n",
    "* Train-testing relies on randomly splitting the training data into two parts.\n",
    "\n",
    "* If this split just happens to be a ‘bad’ split your results might be biased,\n",
    "\n",
    "**Solution:** cross-validation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a solution to a single bad split -- perform the split multiple times -- then train and test -- take the average\n",
    "\n",
    "Example: \n",
    "* 5-fold CV - split the training data into 5 splits (folds)\n",
    "* Use each fold as a test/validation set and the other folds as training set\n",
    "* Multiple splits - even if one is bad it will be balanced out by the others.\n",
    "\n",
    "<img src=\"assets/5fold-xval.png\" height=\"200\" width=\"400\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Accuracies: [ 1.          1.          0.93333333  0.93333333  1.        ]\n",
      "Accuracy: 0.9733333333333334\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "# grab cross validation code\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# get data\n",
    "df = pd.read_csv(\"assets/iris.csv\")\n",
    "X  = df.drop(['id','Species'],axis=1)\n",
    "y = df['Species']\n",
    "\n",
    "# set up our model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(C=1000.0)\n",
    "\n",
    "# do the 5-fold cross validation\n",
    "scores = cross_val_score(model, X, y, cv=5)\n",
    "print(\"Fold Accuracies: {}\".format(scores))\n",
    "print(\"Accuracy: {}\".format(scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation - the Grid Search\n",
    "\n",
    "Where did our model parameters come from in the above examples?  We searched for them!  Therefore:\n",
    "\n",
    "* Finding the best model involves searching for (hyper-)parameter values that give you the best testing/cross-validation accuracy.\n",
    "* This is usually referred to as the *grid search*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sklearn helps us do that efficiently:\n",
    "* Sklearn has a built-in grid search that can optimize the model parameters\n",
    "* The tree has two parameters: criterion and depth\n",
    "* The grid search will find the optimal value for both of these parameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 100.0, 'solver': 'liblinear'}\n",
      "Accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# get data\n",
    "df = pd.read_csv(\"assets/iris.csv\")\n",
    "X  = df.drop(['id','Species'],axis=1)\n",
    "y = df['Species']\n",
    "\n",
    "# setting up grid search\n",
    "model = LogisticRegression(max_iter=10000) \n",
    "param_grid = {'C': [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0],\n",
    "              'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "              }\n",
    "grid = GridSearchCV(model, param_grid, cv=5)\n",
    "\n",
    "# performing grid search \n",
    "grid.fit(X,y)\n",
    "\n",
    "# print out what we found\n",
    "print(\"Best parameters: {}\".format(grid.best_params_))\n",
    "\n",
    "# Get the accuracy\n",
    "# Evaluate the best model\n",
    "# predicting        \n",
    "predict_y = grid.best_estimator_.predict(X)\n",
    "actual_y = y\n",
    "\n",
    "# accuracy          \n",
    "print(\"Accuracy: {}\".format(accuracy_score(actual_y, predict_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
